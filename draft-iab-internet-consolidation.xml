<?xml version="1.0" encoding="US-ASCII"?>
<!DOCTYPE rfc SYSTEM "rfc2629.dtd" [

<!ENTITY RFC1958 SYSTEM "http://xml.resource.org/public/rfc/bibxml/reference.RFC.1958.xml">
]>

<?xml-stylesheet type='text/xsl' href='rfc2629.xslt' ?>
<?rfc strict="yes" ?>
<?rfc toc="yes"?>
<?rfc tocdepth="4"?>
<?rfc symrefs="yes"?>
<?rfc sortrefs="yes" ?>
<?rfc compact="yes" ?>
<?rfc subcompact="no" ?>
<rfc category="info" docName="draft-arkko-iab-internet-consolidation-00" ipr="trust200902">

  <front>

    <title abbrev="Low Latency">Considerations on Internet Consolidation and the Internet Architecture</title>

    <author fullname="Jari Arkko" initials="J." 
            surname="Arkko">
      <organization>Ericsson</organization>

      <address>
        <postal>
          <street></street>
          <city>Kauniainen</city>
          <region></region>
          <code>02700</code>
          <country>Finland</country>
        </postal>
        <email>jari.arkko@piuha.net</email>

      </address>
    </author>
    
    <author fullname="Brian Trammell" initials="B." surname="Trammell">
      <organization>ETH Zurich</organization>
      <address>
        <email>ietf@trammell.ch</email>
      </address>
    </author>
    
    <author fullname="Mark Nottingham" initials="M." surname="Nottingham">
      <address>
        <email>mnot@mnot.net</email>
      </address>
    </author>
    
    <author fullname="Christian Huitema" initials="C." surname="Huitema">
      <organization>Private Octopus Inc.</organization>
      <address>
        <email>huitema@huitema.net</email>
      </address>
    </author>
    
    <author fullname="Martin Thomson" initials="M." surname="Thomson">
      <organization>Mozilla</organization>
      <address>
        <email>martin.thomson@gmail.com</email>
      </address>
    </author>
    
    <author fullname="Jeff Tantsura" initials="J." surname="Tantsura">
      <organization>Nuage Networks</organization>
      <address>
        <email>jefftant.ietf@gmail.com</email>
      </address>
    </author>

    <date month="May" year="2018" />

    <area>Internet</area>

    <workgroup>Internet Engineering Task Force</workgroup>

    <abstract>

      <t>Is Internet traffic consolidating, i.e., moving towards a
      larger fraction of traffic involving a small set of large
      content providers, social networks, and content delivery
      platforms? It certainly appears so. But why is this happening,
      and what might this mean for the Internet? </t>

    </abstract>
  </front>
  
  <middle>
    
    <section title="Introduction">
      
      <t>A recent discussion topic has been the role of smaller
      vs. larger players in the Internet ecosystem. Is Internet
      traffic consolidating, i.e., moving towards a larger fraction of
      traffic involving a small set of large content providers, social
      networks, and content delivery platforms? It certainly appears
      so, though more research on this topic would be welcome.</t>
      
      <t>Why is this happening, and what might this mean for the
      Internet? Are our technology and architecture choices
      affecting some of these trends? Would different technology
      change the trends in some fashion?</t>
      
      <t>Our engineering remit is to focus on technology, but of
      course we also want to understand the implications and
      externalities of the technical arrangements we
      design. Technology affects economics and vice versa. The
      Internet technology community continues to make decisions that
      have ramifications on Internet systems, just as we are subject
      to forces that affect them: the consolidation trend also raises
      relevant and interesting technical and architectural
      questions. </t>
      
      <t>As technologists, one question we have is whether there are
      changes in technology that would help reduce technically-driven
      large-player advantages. This would lead to less dependence on a
      few players and other advantages.</t>

      <t>This memo reviews areas where consolidation may be occurring
      in the Internet, and discusses the potential reasons for
      this. <xref target="factors"/> discusses consolidation and the
      reasons behind the creation of larger entities, and <xref
      target="actions"/> looks at some actions that might alleviate
      the situation.</t>
      
      <t>Note: If you are interested on this or other
      architecture-related topics, please subscribe to the IAB
      architecture-discuss mailing list as one forum for
      discussion.</t>

    </section>

    <section anchor="factors" title="Consolidation">

      <t>In general, an efficient market such as the Internet tends to
      enable winners to take large market shares. Efficiences of scale
      help this process further.</t>
      
      <t>The effects of these factors can be seen, for instance, in
      provisioning of content and services, social media, or cloud
      systems; likewise, ISP services often achieve better efficiency
      at scale. Similar effects can also be seen with operating
      systems, Web browsers, application stores, and other tools.</t>

      <t>At the same time, of course, the Internet allows plenty of
      choice both in these and other areas. Too many or too few
      choices create different kinds of problems.</t>

      <section title="Analysis of Factors">
	
	<t>It would be useful to break these general factors
	and observations down a bit further. In particular,
	it is useful to distinguish market or economic factors
	from technical factors.</t>

	<section title="Economic Factors">
	  
	  <t>The primary economic factors relate to scale, network
	  effects, and lack of barriers for serving larger set of
	  customers. The scaling benefits are natural for many types
	  of businesses. And many Internet-based businesses can
	  potentially serve a very large customer base, as the cost of
	  replicating and delivering their service to new customers or
	  areas is small.</t>
	
	  <t>The network effect, however, has a potentially even more
	  pronounced impact. The network effect means that each
	  additional user in a network adds to the value of the
	  network for all users in the network. As a result, the value
	  of services provided by a large provider can be bigger than
	  the value of those provided by a smaller provider.</t>

	  <t>There is an important distinction between different
	  applications of the network effect, however. Consider e-mail
	  and a social media application, for instance. For e-mail,
	  interoperability between different domains and servers
	  allows anyone to use email with each other, increasing the
	  value of the e-mail application. However, most popular
	  social media applications are closed systems, where there is
	  no interoperability for the application with other
	  systems. As a result, the network effects acrue to the large
	  individual social media systems rather than the users of any
	  system as in e-mail.</t>

	  <t>One of the fundamental design principles of today's
	  Internet was "permissionless innovation", the idea that a
	  network could be simple but still powerful enough that
	  essentially any application could be built on top of it,
	  without a need to arrange any special support from anyone
	  else for the application. This is what enables the
	  end-to-end principle to work, and allows free development of
	  innovative applications over a common network.</t>
	
	  <t>There is an interesting contradiction in the kinds of
	  openness and standards that are needed for the network and
	  the applications. Once the network is powerful enough, it
	  becomes possible to build complex applications that do not
	  need to be similarly open or standardised. We call this the
	  Permissionless Completeness Theorem.</t>
	
        </section>

	<section title="Fundamental Factors">

	  <t>Another class of factors relates to fundamental issues,
	  effects that are inherent to the services that are being
	  provided.</t>
	  
	  <t>One example of such factors is speed of light;
	  low-latency services can fundamentally only be provided
	  through globally distributed data centers. These are often
	  provided built by large organisations, although
	  collaborative and data center or cloud computing service
	  approaches also exist.</t>

	  <t>A similar issue has arisen in recent years around
	  large-scale denial-of-service attacks, and how various
	  entities can deal with them. While the largest attacks
	  affect all players (see, for instance, the Dyn attacks in
	  October 2016), it is also true that large cloud- and content
	  delivery providers can better deal with such attacks due to
	  their scale. This is one reason that attracts many
	  network services to such providers.</t>
	  
	</section>
	
	<section title="Technology Factors">

	  <t>One of the key questions is whether we are seeing
	  developments that are driven by economic factors or whether
	  fundamental reasons or lack available technology drives
	  particular models. For instance, centralised solutions
	  might desirable due to business incentives, or they might be
	  necessary because there is no distributed, collaborative
	  solution.</t>
	  
	  <t>For instance, some technical issues have historically not
	  been easy to solve, such as e-mail spam, which has lead to
	  reliance on non-technical solutions. Today, it is becoming
	  increasingly difficult to run your own mail services,
	  essentially forcing many organisations and individuals to
	  employ larger providers. The issues relate directly to size
	  of entities; no one can afford to disconnect from the
	  largest providers. But as a small entity, there is little
	  leverage to convince peer entities or various supporting
	  white/blacklist entities to deal with you properly.</t>

	  <t>Many Internet services are based on gathering data about
	  users, and using that data for, for instance, targeted
	  advertisements. More data from more users makes it possible
	  to run a service more accurately or with better results;
	  here again scale brings advantages.</t>

	  <t>These advantages are only getting larger with the advent
	  AI- and machine learning -based technologies. The more users
	  a service has, the more data is available for training
	  machine learning models, and the better the service becomes,
	  bringing again more users.</t>
	  
	  <t>A more current trend is that more and more content is becoming
	  available locally, from a content delivery or provider function
	  directly on your own ISP's network. This trend seems strong, and
	  eventually most of the content will be delivered this way,
	  reducing the role that global IP connections across the Internet
	  play. By some metrics this has already happened; what practical
	  - positive or negative - impacts might this have on the Internet
	  technology?</t>
	  
	</section>
	
      </section>
      
    </section>
    
    <section anchor="actions" title="Call for New Work">
      
      <section title="Understanding Assumptions">
	
	<t>Are there assumptions about the Internet architecture that
	no longer hold in a world where larger, more centralised
	entities provide big parts of the Internet service? If the
	world changes, the Internet and its technology/architecture
	may have to match those changes.</t>
	
      </section>
      
      <section title="Technology to Alleviate Advantages of Large-Scale Players">

	<t>It appears that level the playing field for new entrants or
	small players brings potential benefits, and allows new
	innovation solutions to grow large. Are there technical
	solutions that are missing today?</t>
	
	<t>Of course, it may well be that technology improvements are
	hard to come by. Nevertheless, recognising the risks of
	consolidation in both current and proposed future technologies
	is the first step in proactively avoiding those risks where
	possible.</t>

	<t>One avenue where further IETF work would be beneficial is
	better support for federation, which would enable entities (be
	they large or small) to work together to provide global
	services.</t>

	<t>What IETF topics that should be pursued to address some of
	the issues around consolidation?</t>
	
      </section>
      
      <section title="Research on State of the Internet">
	
	<t>Changes in business landscape may also affect standards work
	and processes. Small sets of significant players can drive
	standards work faster, but at the same time the larger entities
	are not as dependent on standardised solutions as smaller ones
	would be.</t>

	<t>This would lead to lower barriers to entry, more entities
	able to provide any particular service on the Internet, less
	dependence on a few players, and more choices and greater
	resilience for the network as a whole.</t>
      
	<t>What research on this topic should be driven forward?</t>
      
      </section>
    </section>
    
    <section anchor="contr" title="Contributors">

      <t>Much of the text in this memo is from a blog article written
      by Jari Arkko, Mark Nottingham, Christian Huitema, Martin
      Thomson, and Brian Trammell for the Internet Architecture Board
      (IAB).</t>
      
    </section>
    <section anchor="ack" title="Acknowledgements">

      <t>The authors would like to thank IAB members, Geoff Huston,
      Gonzalo Camarillo, Olaf Kolkman, and many others for interesting
      discussions in this problem space.</t>
      
    </section>

  </middle>

  <back>

    <references title="Informative References">

      &RFC1958;

    </references>

  </back>
</rfc>
